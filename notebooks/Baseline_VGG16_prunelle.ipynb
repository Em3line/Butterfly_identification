{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58daaecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab68e3d4",
   "metadata": {},
   "source": [
    "# Préparation des échantillons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18d23d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_transformation(df):\n",
    "    data = df.T\n",
    "    data[\"path_to_image\"]=\"../raw_data/IMG/\"+data[\"image_name\"]\n",
    "    data['species'] = data['genus']+' '+data['specific_epithet'] \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "79006a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def X_y_from_df(df, sample_size):\n",
    "    data_sample = df.sample(sample_size, random_state = 818)\n",
    "    image = []\n",
    "\n",
    "    for i in data_sample['path_to_image'] :\n",
    "        img = Image.open(i)\n",
    "        img = img.resize((256,256))\n",
    "        image.append(np.array(img))\n",
    "\n",
    "    X = np.array(image)\n",
    "    y = np.array(data_sample['species'])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "77f59502",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = data_transformation(pd.read_json('../raw_data/splits/train.json'))\n",
    "df_val = data_transformation(pd.read_json('../raw_data/splits/val.json'))\n",
    "df_test = data_transformation(pd.read_json('../raw_data/splits/test.json'))\n",
    "\n",
    "X_val, y_val = X_y_from_df(df_val, 200)\n",
    "X_test, y_test = X_y_from_df(df_test, 200)\n",
    "X_train, y_train = X_y_from_df(df_train, 1000)\n",
    "\n",
    "y_train = y_train.reshape(1000, 1)\n",
    "y_val = y_val.reshape(200, 1)\n",
    "y_test = y_test.reshape(200, 1)\n",
    "\n",
    "\n",
    "X_train = preprocess_input(X_train)\n",
    "X_val = preprocess_input(X_val)\n",
    "X_test = preprocess_input(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9f8af777",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse=False, handle_unknown = 'ignore')\n",
    "ohe.fit(y_train)\n",
    "y_train_cat = ohe.transform(y_train)\n",
    "y_val_cat = ohe.transform(y_val)\n",
    "y_test_cat = ohe.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cba1af8",
   "metadata": {},
   "source": [
    "# Lancement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2fd27521",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras import optimizers, layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "def model_VGG16( X_train, y_train_cat, X_val, y_val_cat, X_test, y_test_cat, image_size,  patience=2, learning_rate=0.001, nb_epochs=15, nb_couches_dense_layer=130):\n",
    "    \n",
    "    model = VGG16(weights=\"imagenet\", include_top=False, input_shape = image_size)\n",
    "    # Set the first layers to be untrainable\n",
    "    model.trainable = False\n",
    "    \n",
    "    #add last layers\n",
    "    flatten_layer = layers.Flatten()\n",
    "    dense_layer = layers.Dense(nb_couches_dense_layer, activation='relu')\n",
    "    prediction_layer = layers.Dense(248, activation='softmax')\n",
    "    model = models.Sequential([\n",
    "        model,\n",
    "        flatten_layer,\n",
    "        dense_layer,\n",
    "        prediction_layer\n",
    "    ])\n",
    "    \n",
    "    #build model\n",
    "    opt = optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    #set earlystopping\n",
    "    es = EarlyStopping(monitor='val_loss', mode='max', patience=patience, verbose=1, restore_best_weights=True)\n",
    "    \n",
    "    #launch model\n",
    "    history = model.fit(X_train, y_train_cat, \n",
    "                    validation_data=(X_val, y_val_cat), \n",
    "                    epochs=nb_epochs, \n",
    "                    batch_size=16, \n",
    "                    callbacks=[es])\n",
    "    \n",
    "    #evaluate model\n",
    "    res_vgg = model.evaluate(X_test, y_test_cat)\n",
    "    \n",
    "    test_accuracy_vgg = res_vgg[-1]\n",
    "    \n",
    "    return (f\"test_accuracy_vgg = {round(test_accuracy_vgg,2)*100} %\"), history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f94475",
   "metadata": {},
   "source": [
    "# Courbes d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3aafbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, title='', axs=None, exp_name=\"\"):\n",
    "    if axs is not None:\n",
    "        ax1, ax2 = axs\n",
    "    else:\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    if len(exp_name) > 0 and exp_name[0] != '_':\n",
    "        exp_name = '_' + exp_name\n",
    "    ax1.plot(history.history['loss'], label='train' + exp_name)\n",
    "    ax1.plot(history.history['val_loss'], label='val' + exp_name)\n",
    "    #ax1.set_ylim(0., 2.2)\n",
    "    ax1.set_title('loss')\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.plot(history.history['accuracy'], label='train accuracy'  + exp_name)\n",
    "    ax2.plot(history.history['val_accuracy'], label='val accuracy'  + exp_name)\n",
    "    #ax2.set_ylim(0.25, 1.)\n",
    "    ax2.set_title('Accuracy')\n",
    "    ax2.legend()\n",
    "    return (ax1, ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28559b36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3422796",
   "metadata": {},
   "source": [
    "# Historique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "329e77a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x15e1ab0d0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6569cb16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256, 3)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "accc3500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "63/63 [==============================] - 475s 8s/step - loss: 7.9878 - accuracy: 0.0370 - val_loss: 4.4140 - val_accuracy: 0.0300\n",
      "Epoch 2/15\n",
      "63/63 [==============================] - 518s 8s/step - loss: 5.0610 - accuracy: 0.0680 - val_loss: 4.2911 - val_accuracy: 0.0450\n",
      "Epoch 3/15\n",
      "63/63 [==============================] - 508s 8s/step - loss: 4.8457 - accuracy: 0.1010 - val_loss: 4.0548 - val_accuracy: 0.0950\n",
      "Epoch 4/15\n",
      "63/63 [==============================] - 782s 12s/step - loss: 4.6902 - accuracy: 0.1140 - val_loss: 4.0477 - val_accuracy: 0.0750\n",
      "Epoch 5/15\n",
      "63/63 [==============================] - 467s 7s/step - loss: 4.5394 - accuracy: 0.1260 - val_loss: 4.1062 - val_accuracy: 0.0750\n",
      "Epoch 6/15\n",
      "63/63 [==============================] - 507s 8s/step - loss: 4.4539 - accuracy: 0.1270 - val_loss: 3.8763 - val_accuracy: 0.1000\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "7/7 [==============================] - 73s 10s/step - loss: 4.4448 - accuracy: 0.0300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'test_accuracy_vgg = 3.0 %'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_VGG16(X_train, y_train_cat, X_val, y_val_cat, X_test, y_test_cat, X_train[0].shape, 5, 0.001, 15, 130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c8d144",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = load_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96057c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_nontrainable_layers(model):\n",
    "    # Set the first layers to be untrainable\n",
    "    model.trainable = False\n",
    "    \n",
    "    return model\n",
    "\n",
    "model\n",
    "model = set_nontrainable_layers(model)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4c2ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def add_last_layers(model):\n",
    "    '''Take a pre-trained model, set its parameters as non-trainables, and add additional trainable layers on top'''\n",
    "    # $CHALLENGIFY_BEGIN\n",
    "    base_model = set_nontrainable_layers(model)\n",
    "    flatten_layer = layers.Flatten()\n",
    "    dense_layer = layers.Dense(130, activation='relu')\n",
    "    prediction_layer = layers.Dense(248, activation='softmax')\n",
    "    \n",
    "    \n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        flatten_layer,\n",
    "        dense_layer,\n",
    "        prediction_layer\n",
    "    ])\n",
    "    # $CHALLENGIFY_END\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c651dada",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = add_last_layers(model)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b24d911",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "def build_model():\n",
    "    # $CHALLENGIFY_BEGIN    \n",
    "    model = load_model()\n",
    "    model = add_last_layers(model)\n",
    "    \n",
    "    opt = optimizers.Adam(learning_rate=1e-3)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "    # $CHALLENGIFY_END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c91629d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee1121c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "def load_model():\n",
    "    # $CHALLENGIFY_BEGIN\n",
    "    model = VGG16(weights=\"imagenet\", include_top=False, input_shape=image[0].shape)\n",
    "    # $CHALLENGIFY_END\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e58f45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285fd348",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2d83b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a636cfc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373dc7d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccbd91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8494bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b744d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9794fd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58c31b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='max', patience=2, verbose=1, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train, y_cat, \n",
    "                    validation_data=(X_val, y_val_cat), \n",
    "                    epochs=20, \n",
    "                    batch_size=16, \n",
    "                    callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3430842f",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_vgg = model.evaluate(X_test, y_test_cat)\n",
    "\n",
    "test_accuracy_vgg = res_vgg[-1]\n",
    "\n",
    "print(f\"test_accuracy_vgg = {round(test_accuracy_vgg,2)*100} %\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
